{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "pix2struct-chart\n",
        "\n",
        "```\n",
        "# Sformatowano jako kod\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "KFNLZK93fTGX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "donut-base"
      ],
      "metadata": {
        "id": "y-_kglejMtYY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "from transformers import DonutProcessor, VisionEncoderDecoderModel\n",
        "from PIL import Image\n",
        "import torch\n",
        "\n",
        "# Zmień na naver-clova-ix/donut-base, aby mieć bardziej uniwersalny model\n",
        "processor = DonutProcessor.from_pretrained(\"naver-clova-ix/donut-base\")\n",
        "model = VisionEncoderDecoderModel.from_pretrained(\"naver-clova-ix/donut-base\")\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(device)\n",
        "\n",
        "# Załaduj swój obraz z wykresem\n",
        "image_path = \"./path_to_image/sample_chart.png\"\n",
        "image = Image.open(image_path).convert(\"RGB\")\n",
        "\n",
        "# Przygotowanie danych wejściowych\n",
        "task_prompt = \"<s>\"\n",
        "decoder_input_ids = processor.tokenizer(task_prompt, add_special_tokens=False, return_tensors=\"pt\").input_ids\n",
        "\n",
        "pixel_values = processor(image, return_tensors=\"pt\").pixel_values\n",
        "\n",
        "# Generowanie opisu\n",
        "outputs = model.generate(\n",
        "    pixel_values.to(device),\n",
        "    decoder_input_ids=decoder_input_ids.to(device),\n",
        "    max_length=model.decoder.config.max_position_embeddings,\n",
        "    pad_token_id=processor.tokenizer.pad_token_id,\n",
        "    eos_token_id=processor.tokenizer.eos_token_id,\n",
        "    use_cache=True,\n",
        "    bad_words_ids=[[processor.tokenizer.unk_token_id]],\n",
        "    return_dict_in_generate=True,\n",
        ")\n",
        "\n",
        "sequence = processor.batch_decode(outputs.sequences)[0]\n",
        "sequence = sequence.replace(processor.tokenizer.eos_token, \"\").replace(processor.tokenizer.pad_token, \"\")\n",
        "sequence = re.sub(r\"<.*?>\", \"\", sequence, count=1).strip()\n",
        "print(sequence)\n"
      ],
      "metadata": {
        "id": "HwII13hKT6md"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from transformers import DonutProcessor, VisionEncoderDecoderModel\n",
        "from PIL import Image\n",
        "import torch\n",
        "\n",
        "# Załaduj model i procesor\n",
        "processor = DonutProcessor.from_pretrained(\"naver-clova-ix/donut-base-finetuned-docvqa\")\n",
        "model = VisionEncoderDecoderModel.from_pretrained(\"naver-clova-ix/donut-base-finetuned-docvqa\")\n",
        "\n",
        "# Wykorzystaj GPU, jeśli dostępne\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(device)\n",
        "\n",
        "# Załaduj jeden obraz (np. dokument) za pomocą Pillow (PIL)\n",
        "image_path = \"./path_to_image/sample_image.png\"  # Podaj ścieżkę do swojego obrazu\n",
        "image = Image.open(image_path).convert(\"RGB\")  # Konwertuj obraz do formatu RGB\n",
        "\n",
        "# Przygotuj pytanie i dane wejściowe do modelu\n",
        "task_prompt = \"<s_docvqa><s_question>{user_input}</s_question><s_answer>\"\n",
        "question = \"When is the coffee break?\"  # Twoje pytanie dotyczące obrazu\n",
        "prompt = task_prompt.replace(\"{user_input}\", question)\n",
        "decoder_input_ids = processor.tokenizer(prompt, add_special_tokens=False, return_tensors=\"pt\").input_ids\n",
        "\n",
        "# Przetwórz obraz za pomocą procesora\n",
        "pixel_values = processor(image, return_tensors=\"pt\").pixel_values\n",
        "\n",
        "# Generowanie wyników\n",
        "outputs = model.generate(\n",
        "    pixel_values.to(device),\n",
        "    decoder_input_ids=decoder_input_ids.to(device),\n",
        "    max_length=model.decoder.config.max_position_embeddings,\n",
        "    pad_token_id=processor.tokenizer.pad_token_id,\n",
        "    eos_token_id=processor.tokenizer.eos_token_id,\n",
        "    use_cache=True,\n",
        "    bad_words_ids=[[processor.tokenizer.unk_token_id]],\n",
        "    return_dict_in_generate=True,\n",
        ")\n",
        "\n",
        "# Przetwarzanie wyników\n",
        "sequence = processor.batch_decode(outputs.sequences)[0]\n",
        "sequence = sequence.replace(processor.tokenizer.eos_token, \"\").replace(processor.tokenizer.pad_token, \"\")\n",
        "sequence = re.sub(r\"<.*?>\", \"\", sequence, count=1).strip()  # Usuń pierwszy token startowy zadania\n",
        "\n",
        "# Wyświetl odpowiedź w formacie JSON\n",
        "print(processor.token2json(sequence))\n"
      ],
      "metadata": {
        "id": "KbXn2wDnT6pC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iDueAHPLT6se"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r9a35De7gmul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oeMBDJkxgmxo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import requests\n",
        "from transformers import AutoProcessor, Pix2StructForConditionalGeneration\n",
        "\n",
        "processor = AutoProcessor.from_pretrained(\"google/pix2struct-textcaps-base\")\n",
        "model = Pix2StructForConditionalGeneration.from_pretrained(\"google/pix2struct-textcaps-base\")\n",
        "\n",
        "url = \"https://www.ilankelman.org/stopsigns/australia.jpg\"\n",
        "image = Image.open(requests.get(url, stream=True).raw)\n",
        "\n",
        "inputs = processor(images=image, return_tensors=\"pt\")\n",
        "\n",
        "# autoregressive generation\n",
        "generated_ids = model.generate(**inputs, max_new_tokens=50)\n",
        "generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
        "print(generated_text)\n",
        "\n",
        "# conditional generation\n",
        "text = \"A picture of\"\n",
        "inputs = processor(text=text, images=image, return_tensors=\"pt\", add_special_tokens=False)\n",
        "\n",
        "generated_ids = model.generate(**inputs, max_new_tokens=50)\n",
        "generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
        "print(generated_text)"
      ],
      "metadata": {
        "id": "NqFg0hStgm1H"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}