{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from transformers import DonutProcessor, VisionEncoderDecoderModel\n",
        "from safetensors.torch import load_file\n",
        "from PIL import Image\n",
        "import torch\n",
        "\n",
        "# Ścieżki do procesora, modelu i wag safetensors\n",
        "processor_path = \"naver-clova-ix/donut-base-finetuned-docvqa\"\n",
        "safetensors_weights_path = \"./naver-clova-ix/donut-base-finetuned-docvqa/pytorch_model.safetensors\"\n",
        "image_path = \"./path_to_image/sample_image.png\"  # Ścieżka do obrazu\n",
        "\n",
        "# Załaduj procesor\n",
        "processor = DonutProcessor.from_pretrained(processor_path)\n",
        "\n",
        "# Załaduj wagi safetensors\n",
        "state_dict = load_file(safetensors_weights_path)\n",
        "\n",
        "# Załaduj model z wagami safetensors\n",
        "model = VisionEncoderDecoderModel.from_pretrained(processor_path, state_dict=state_dict)\n",
        "\n",
        "# Przenieś model na GPU lub CPU\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(device)\n",
        "\n",
        "# Załaduj obraz\n",
        "image = Image.open(image_path).convert(\"RGB\")\n",
        "\n",
        "# Przygotowanie danych wejściowych\n",
        "task_prompt = \"<s_docvqa><s_question>{user_input}</s_question><s_answer>\"\n",
        "question = \"When is the coffee break?\"\n",
        "prompt = task_prompt.replace(\"{user_input}\", question)\n",
        "decoder_input_ids = processor.tokenizer(prompt, add_special_tokens=False, return_tensors=\"pt\").input_ids\n",
        "\n",
        "pixel_values = processor(image, return_tensors=\"pt\").pixel_values\n",
        "\n",
        "# Generowanie tekstu na podstawie obrazu\n",
        "outputs = model.generate(\n",
        "    pixel_values.to(device),\n",
        "    decoder_input_ids=decoder_input_ids.to(device),\n",
        "    max_length=model.decoder.config.max_position_embeddings,\n",
        "    pad_token_id=processor.tokenizer.pad_token_id,\n",
        "    eos_token_id=processor.tokenizer.eos_token_id,\n",
        "    use_cache=True,\n",
        "    bad_words_ids=[[processor.tokenizer.unk_token_id]],\n",
        "    return_dict_in_generate=True,\n",
        ")\n",
        "\n",
        "# Przetwarzanie wyników\n",
        "sequence = processor.batch_decode(outputs.sequences)[0]\n",
        "sequence = sequence.replace(processor.tokenizer.eos_token, \"\").replace(processor.tokenizer.pad_token, \"\")\n",
        "sequence = re.sub(r\"<.*?>\", \"\", sequence, count=1).strip()  # Usuń pierwszy token startowy zadania\n",
        "\n",
        "# Wyświetl wynik w formacie JSON\n",
        "print(processor.token2json(sequence))\n"
      ],
      "metadata": {
        "id": "DtUm7WHVaG3D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PWVC42pcaG5a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8Lzby_UvaG7Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IA8S8Qe4aG--"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}